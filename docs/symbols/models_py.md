---
tags: #class-chatchunk #class-modelconfig #class-modeltype #core #has-classes #has-functions #important #python
created: 2025-11-22T21:46:16.516050
source: models.py
type: symbol-documentation
---

# models.py

**Path**: `models.py`

## Symbols

### Classes
- [[ModelType]]
- [[ModelConfig]]
- [[ChatChunk]]
- [[ChatGenerationResult]]
- [[LiteLLMChatWrapper]]
- [[AsyncAIChatReplacement]]
- [[BrowserCompatibleChatWrapper]]
- [[LiteLLMEmbeddingWrapper]]
- [[LocalSentenceTransformerWrapper]]

### Functions
- [[turn_off_logging]]
- [[get_api_key]]
- [[get_rate_limiter]]
- [[_is_transient_litellm_error]]
- [[apply_rate_limiter_sync]]
- [[_get_litellm_chat]]
- [[_get_litellm_embedding]]
- [[_parse_chunk]]
- [[_adjust_call_args]]
- [[_merge_provider_defaults]]
- [[get_chat_model]]
- [[get_browser_model]]
- [[get_embedding_model]]

### Interfaces
None

## Imports
- `dataclass, field
from enum import Enum
import logging
import os
from typing import `
- `completion, acompletion, embedding
import litellm
import openai
from litellm`
- `dotenv
from python`
- `load_dotenv
from python`
- `RateLimiter
from python`
- `dirty_json, browser_use_monkeypatch

from langchain_core`
- `ChatGenerationChunk
from langchain_core`
- `Embeddings
from sentence_transformers import SentenceTransformer
from pydantic import ConfigDict


`
- `ChatOllama, ChatOpenRouter, ChatGoogle, ChatAnthropic, ChatGroq, ChatOpenAI

class BrowserCompatibleChatWrapper`

## References
[[ModelType]]
[[ModelConfig]]
[[ChatChunk]]
[[ChatGenerationResult]]
[[LiteLLMChatWrapper]]
[[AsyncAIChatReplacement]]
[[BrowserCompatibleChatWrapper]]
[[LiteLLMEmbeddingWrapper]]
[[LocalSentenceTransformerWrapper]]
[[turn_off_logging]]

## Memory Integration
- Memory Area: #memory-main
- Auto-tagged: 2025-11-22
- Symbol Count: 31

## Related Files
<!-- Auto-generated by relationship analyzer -->
