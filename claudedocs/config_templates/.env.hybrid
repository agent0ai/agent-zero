# Agent Zero Configuration - Hybrid (Ollama + Claude Fallback)
# Copy this to .env for maximum flexibility: free local + cloud backup

# ============================================
# Agent Zero Runtime ID (keep existing)
# ============================================
A0_PERSISTENT_RUNTIME_ID=2b028188e762c1f90dc8addb6acbf493

# ============================================
# Primary: Ollama (Local, Free)
# ============================================
# Main workhorse: Local Ollama for cost savings
OLLAMA_API_BASE=http://host.docker.internal:11434

# Make sure you have models pulled:
# ollama pull qwen2.5-coder:7b    # Primary code model
# ollama pull gemma2:2b            # Fast utility model

# ============================================
# Backup: Cloud APIs (for complex tasks)
# ============================================
# OpenRouter: Best flexibility (200+ models including Claude)
OPENROUTER_API_KEY=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

# Gemini: Google's models (already configured)
GEMINI_API_KEY=AIzaSyBHOLoN8pCBhKXqHqaKmQXqPCYPgPLjxl8

# Anthropic: Direct Claude access (if you have it)
# ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxxxxxxxxxx

# ============================================
# Google Cloud (if using Vertex AI)
# ============================================
VERTEX_PROJECT=andre-467020
VERTEX_LOCATION=us-central1

# ============================================
# System Configuration
# ============================================
DEFAULT_USER_UTC_OFFSET_MINUTES=-180
DEFAULT_USER_TIMEZONE=America/Sao_Paulo

# Memory Configuration
MEMORY_SUBDIR=mlcreator

# ============================================
# Model Selection Strategy
# ============================================
# Set in docker-compose-fresh.yml:
#
# Default: Use free Ollama
# CHAT_MODEL_PROVIDER: "ollama"
# CHAT_MODEL_NAME: "qwen2.5-coder:7b"
# UTIL_MODEL_PROVIDER: "ollama"
# UTIL_MODEL_NAME: "gemma2:2b"
#
# For complex tasks: Switch to Claude via Web UI
# Settings → Chat Model → Provider: "openrouter"
#                      → Name: "anthropic/claude-3.5-sonnet"
#
# Benefits:
# ✅ 90% of tasks: Free local inference (Ollama)
# ✅ Complex reasoning: Premium models (Claude/GPT-4)
# ✅ No lock-in: Switch providers anytime via Web UI
# ✅ Cost optimization: Only pay for what you really need
